[meta
  title:"What is Dimensionality Reduction?"
  description:"An intuitive guide to the statistical technique." /]


[var name:"scrollState" value:"initial" /]


[Scroller currentState:scrollState]

  [Graphic]
    [DRComponent state:scrollState /]
  [/Graphic]

  [Step state:"initial"]
    [Header
      title:"What is Dimensionality Reduction?"
      subtitle:"An intuitive guide to the statistical technique."
      date:"July 12, 2018"
      authors:`[
        { name: "Matthew Conlen", link: "https://twitter.com/mathisonian" },
        { name: "Fred Hohman", link: "http://twitter.com/fredhohman" }
      ]` /]
  [/Step]

  [Step]

    // intro
    [Dimensionality reduction](https://en.wikipedia.org/wiki/Dimensionality_reduction) is a common yet powerful technique used in data mining, machine learning, and now more broadly, AI research and applications.
    The goal of dimsionality reduction, a subset of unsupervised learning, is to infer a function to describe the structure of "unlabeled" data, i.e. data that has no categorization.
    This presents a challenge for all dimsionality reduction techniques, since considered data is unlabelled, there is no straightforward way to evaluate the accuracy of the embedding or structure that is produced by the reduction algorithm.

    *need more motivation examples: why do you do DR? preprocessing, feature reduction, more important but non interpretable features*

    We can describe the technique using a data-centric view.
    Consider a datseta typically represented as a matrix
    [Equation display:false]X[/Equation], where
    [Equation display:false]X[/Equation]
    is of size
    [Equation display:false]m \times n[/Equation], where
    [Equation display:false]m[/Equation] is the number of rows of
    [Equation display:false]X[/Equation], and
    [Equation display:false]n[/Equation] is the number of columns.
    Typically, the rows are *data points* and the columns are *features*.
    Dimesionality reduction will reduce the number of eatures of each data point, turning
    [Equation display:false]X[/Equation] into a new matrix,
    [Equation display:false]X'[/Equation], of size 
    [Equation display:false]m \times d[/Equation], where
    [Equation display:false]d < n[/Equation].

    For example, say [Equation display:false]m=n[/Equation], that is
    [Equation display:false]X[/Equation] is a square matrix.
    Performing dimesionality reduction on
    [Equation display:false]X[/Equation] will change it from a square matrix to a tall, thin, rectangular matrix.

    [Equation display:false]
    \begin{bmatrix}
    x & x & x \\
    x & x & x \\
    x & x & x 
    \end{bmatrix}
    \implies
    \begin{bmatrix}
    x & x \\
    x & x \\
    x & x 
    \end{bmatrix}
    [/Equation]

    [br /]
    *Reducing a 3x3 square matrix to a 3x2 matrix. Each data point only has two features now, i.e., each point has been reduced from a 3 dimensional vector to a 2 dimensional vector.* 

    [Cite reference:"test1"  /]

    [Cite reference:"test2"  /]

    [Cite reference:`["test1", "test2"]`  /]

    ## Example
    Let's start with an example.
    Consider a dataset of artworks from the [The Museum of Modern Art (MoMA) Collection](https://github.com/MuseumofModernArt/collection).
    This dataset contains 134,455 records, representing all of the works that have been accessioned into MoMAâ€™s collection and cataloged in their database.
    Each artwork includes basic metadata, such as its title, artist, date made, medium, dimensions, and date acquired by the Museum.
    That means each artowkr is represntation by a number of different *features*.

    *Show tableâ€”introduce rows (data points) and columns (features)*.


  [/Step]

  [Step state:"1d"]
    Wooo 1D and stuff!
  [/Step]


  [Step state:"pca-1"]
    back to
  [/Step]

[/Scroller]

Some other stuff can go here

[CustomD3Component /]

[CustomComponent /]

## Yeah, stuff

### Maybe the graphic comes back?

[div style:`{height:'30vh', width:'100%'}`/] // just get some whitespace

[var name:"scrollState2" value:"initial" /]


[Scroller currentState:scrollState2]

  [Graphic]
    [DRComponent state:scrollState2 fill:"blue" /]
  [/Graphic]

  [Step state:"initial"]
    # Second Graphic! ðŸ™ƒ
  [/Step]

  [Step state:"1d"]
    Wooo 1D and stuff!
  [/Step]


  [Step state:"pca-1"]
    back to
  [/Step]

[/Scroller]

If you have a data set and wish to understand it better, there are a number of different algorithms and implementations to perform dimensionality reduction.
In Python, the scikit-learn package provided implementions for [unsupervised dimensionality reduction](http://scikit-learn.org/stable/modules/unsupervised_reduction.html), as well as [manifold learning](http://scikit-learn.org/stable/modules/manifold.html): an approach to non-linear dimensionality reduction.

### Acknowledgements
* This article was created using [Idyll](https://idyll-lang.org).
* The source code is available on [Github](https://github.com/mathisonian/dimensionality-reduction).

[References /]
